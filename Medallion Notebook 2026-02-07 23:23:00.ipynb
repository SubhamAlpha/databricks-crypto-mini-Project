{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "280377f8-3479-4cf7-bd94-c034d9aa89a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f603fbfc-a551-4386-a7d6-ce63fdeb702f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DATA INJESTION FROM API"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "# 1. Fetch data directly into memory\n",
    "URL = \"https://api.coingecko.com/api/v3/coins/markets\"\n",
    "params = {'vs_currency': 'usd', 'order': 'market_cap_desc', 'per_page': 50}\n",
    "response = requests.get(URL, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # 2. Convert to Spark DataFrame without saving a file\n",
    "    json_data = response.json()\n",
    "    spark_df = spark.createDataFrame(pd.DataFrame(json_data))\n",
    "    \n",
    "    # 3. Add metadata and save as a Managed Delta Table\n",
    "    bronze_df = spark_df.withColumn(\"ingested_at\", current_timestamp())\n",
    "    bronze_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze_crypto\")\n",
    "    \n",
    "    print(\"Table 'bronze_crypto' created successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d0f9297-1c32-4c71-8326-8abd885be4e2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 3"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(\"bronze_crypto\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "510a6a54-d75b-4af2-a820-af9930adf73d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Cleanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca75915f-23e6-4461-b250-78ff08b601eb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Silver Layer Transformation"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, current_timestamp\n",
    "\n",
    "def transform_bronze_to_silver():\n",
    "    # 1. Read from the Bronze Table\n",
    "    bronze_df = spark.table(\"bronze_crypto\")\n",
    "    \n",
    "    # 2. Clean and Transform\n",
    "    silver_df = (bronze_df\n",
    "        .select(\n",
    "            col(\"id\").alias(\"coin_id\"),\n",
    "            col(\"symbol\"),\n",
    "            col(\"name\"),\n",
    "            col(\"current_price\").cast(\"double\").alias(\"price_usd\"),\n",
    "            col(\"market_cap\").cast(\"long\"),\n",
    "            col(\"total_volume\").cast(\"long\").alias(\"daily_volume\"),\n",
    "            col(\"last_updated\").cast(\"timestamp\")\n",
    "        )\n",
    "        # Filter: Only keep coins with a valid price\n",
    "        .filter(col(\"price_usd\") > 0)\n",
    "        # Add a calculated column: Is it a high volume coin? (e.g., > $100M)\n",
    "        .withColumn(\"is_high_volume\", when(col(\"daily_volume\") > 100000000, True).otherwise(False))\n",
    "        # Add a processing timestamp for the Silver layer\n",
    "        .withColumn(\"silver_processed_at\", current_timestamp())\n",
    "    )\n",
    "    \n",
    "    # 3. Save as the Silver Table\n",
    "    silver_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_crypto\")\n",
    "    \n",
    "    print(\"Successfully created 'silver_crypto' table!\")\n",
    "\n",
    "transform_bronze_to_silver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a2c2e90-f16c-4f5c-b7be-b18cf16b9ddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGlzcGxheShzcGFyay50YWJsZSgic2lsdmVyX2NyeXB0byIpKQ==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView09bdc37\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView09bdc37\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView09bdc37\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView09bdc37) SELECT `name`,`daily_volume` FROM q GROUP BY `daily_volume`,`name`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView09bdc37\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "daily_volume",
             "id": "column_91855369105"
            },
            "x": {
             "column": "name",
             "id": "column_91855369104"
            },
            "y": []
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "legend": {
            "enabled": true,
            "placement": "right",
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {},
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "56742316-4433-4dd5-8661-d6f00f44f9d4",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 6.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "name",
           "type": "column"
          },
          {
           "column": "daily_volume",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "name",
           "type": "column"
          },
          {
           "column": "daily_volume",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.table(\"silver_crypto\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d21c430e-4c99-4314-a7a1-a880f2cec8b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, count, round\n",
    "\n",
    "def create_gold_layer():\n",
    "    # 1. Read from Silver\n",
    "    silver_df = spark.table(\"silver_crypto\")\n",
    "    \n",
    "    # 2. Aggregate: Average Price and Count by High Volume status\n",
    "    gold_df = (silver_df\n",
    "        .groupBy(\"is_high_volume\")\n",
    "        .agg(\n",
    "            count(\"coin_id\").alias(\"coin_count\"),\n",
    "            round(avg(\"price_usd\"), 2).alias(\"avg_price_usd\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 3. Save as Gold Table\n",
    "    gold_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold_crypto_stats\")\n",
    "    \n",
    "    print(\"Gold Layer Created: Summary stats ready for reporting.\")\n",
    "\n",
    "    \n",
    "create_gold_layer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3299ba5e-db42-4d6a-b66b-e69a348205ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGlzcGxheShzcGFyay50YWJsZSgiZ29sZF9jcnlwdG9fc3RhdHMiKSk=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView3f26922\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView3f26922\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView3f26922\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView3f26922) SELECT `is_high_volume`,SUM(`coin_count`) `column_9185536998`,`is_high_volume` FROM q GROUP BY `is_high_volume`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView3f26922\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Data Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "is_high_volume",
             "id": "column_9185536999"
            },
            "x": {
             "column": "is_high_volume",
             "id": "column_91855369101"
            },
            "y": [
             {
              "column": "coin_count",
              "id": "column_9185536998",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_9185536998": {
             "name": "avg_price_usd",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "043174ef-bc00-46fd-9268-16785ac134aa",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "is_high_volume",
           "type": "column"
          },
          {
           "column": "is_high_volume",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "is_high_volume",
           "type": "column"
          },
          {
           "alias": "column_9185536998",
           "args": [
            {
             "column": "coin_count",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "column": "is_high_volume",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.table(\"gold_crypto_stats\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dc13dac-0b6a-4922-bc70-dfd150280645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Author : Subham Nanda"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Medallion Notebook 2026-02-07 23:23:00",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
